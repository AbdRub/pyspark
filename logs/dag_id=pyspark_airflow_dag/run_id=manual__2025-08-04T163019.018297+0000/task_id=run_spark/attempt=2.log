{"timestamp":"2025-08-04T16:32:47.583003","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-08-04T16:32:47.586520","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/spark_example_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-04T16:32:51.241135Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"task"}
{"timestamp":"2025-08-04T16:32:51.242722Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"task"}
{"timestamp":"2025-08-04T16:32:51.584092Z","level":"error","event":"25/08/04 16:32:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"task"}
{"timestamp":"2025-08-04T16:33:01.661747","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"PySparkTypeError","exc_value":"[CANNOT_MERGE_TYPE] Can not merge type `DoubleType` and `LongType`.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":877,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1164,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":217,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":240,"name":"execute_callable"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/callback_runner.py","lineno":81,"name":"run"},{"filename":"/opt/airflow/dags/spark_example_dag.py","lineno":11,"name":"run_spark_callable"},{"filename":"/opt/airflow/dags/spark_jobs/spark_task.py","lineno":11,"name":"run_spark_job"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":1443,"name":"createDataFrame"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":1485,"name":"_create_dataframe"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":1093,"name":"_createFromLocal"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":955,"name":"_inferSchemaFromList"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/types.py","lineno":1803,"name":"_merge_type"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/types.py","lineno":1793,"name":"_merge_type"}],"is_group":false,"exceptions":[]}]}
